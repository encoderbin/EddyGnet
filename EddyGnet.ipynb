{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2ac417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pickle\n",
    "import joblib\n",
    "import math\n",
    "from copy import *\n",
    "c = deepcopy\n",
    "device = torch.device('cuda:0')\n",
    "import time\n",
    "from torch import optim\n",
    "from data.DataProcess import MyDataset   \n",
    "\n",
    "\n",
    "\n",
    "from data.mydata_get import my_TrajectoryDataset_csv    \n",
    "from model.my_E_D_STGCN import make_model\n",
    "from model import scikit_wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd94d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc256fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "\n",
    "parser.add_argument('--obs_len', type=int, default=15) \n",
    "parser.add_argument('--pred_len', type=int, default=7) \n",
    "parser.add_argument('--teacher_len', type=int, default=3) \n",
    "parser.add_argument('--feature_num', type=int, default=8) \n",
    "parser.add_argument('--window_skip', type=int, default=1) \n",
    "parser.add_argument('--rel_if', type=bool, default=False) \n",
    "parser.add_argument('--data_delete_if', type=bool, default=True)  \n",
    "parser.add_argument('--data_get_if', type=bool, default=False) \n",
    "parser.add_argument('--dec_in', type=int, default=8) \n",
    "parser.add_argument('--rep_triloss_len', type=int, default=20) \n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--use_generator', type=bool, default=True) \n",
    "parser.add_argument('--use_LayerNorm', type=bool, default=True) \n",
    "parser.add_argument('--residual_connection', type=bool, default=True) \n",
    "\n",
    "parser.add_argument('--dropout', type=int, default=0.3) \n",
    "parser.add_argument('--num_layers_E', type=int, default=1)\n",
    "parser.add_argument('--num_layers_d', type=int, default=1) \n",
    "\n",
    "parser.add_argument('--layernorm_size', type=int, default=8) \n",
    "\n",
    "parser.add_argument('--dim_hid', type=int, default=192) \n",
    "parser.add_argument('--dim_out', type=int, default=2) \n",
    "parser.add_argument('--dilation_factor', type=int, default=2) \n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--MSE_if', type=bool, default=True) \n",
    "parser.add_argument('--representation_if', type=bool, default=True) \n",
    "parser.add_argument('--Encoder_ESG', type=bool, default=True) \n",
    "parser.add_argument('--Encoder_SGCN', type=bool, default=True) \n",
    "parser.add_argument('--output_informer', type=bool, default=False) \n",
    "parser.add_argument('--output_TCN', type=bool, default=False) \n",
    "parser.add_argument('--output_LSTM', type=bool, default=True) \n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--decoder_embedding', type=bool, default=True) \n",
    "parser.add_argument('--encoder_embedding', type=bool, default=True) \n",
    "\n",
    "# parser.add_argument('--Flag', type=str, default='train') \n",
    "parser.add_argument('--train_without_stand', type=bool, default=False) \n",
    "parser.add_argument('--do_train', type=bool, default=False) \n",
    "parser.add_argument('--do_train_from_last', type=bool, default=False) \n",
    "parser.add_argument('--epochs', type=int, default=150) #  \n",
    "parser.add_argument('--early_stop',type=bool,default=True,help='')\n",
    "parser.add_argument('--early_stop_steps',type=int,default=3,help='')\n",
    "parser.add_argument('--batch_size', type=int, default=1) \n",
    "parser.add_argument('--batch_loss', type=int, default=1,  \n",
    "                    help='minibatch size')\n",
    "\n",
    "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=True) \n",
    "args, _ = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52189b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_dir='./data/raw-30-day.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92134d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.representation_if:\n",
    "    args.feature_num=160\n",
    "    args.dec_in=160\n",
    "if args.output_LSTM:\n",
    "    args.decoder_embedding=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9367ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1693  \n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80798109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(my_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2400ea58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae8b796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e37bbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5406dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_first = df.groupby('track', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ede97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_judge(C,B,A):\n",
    "    print('A',A)\n",
    "    print('B',B)\n",
    "    print('C',C)\n",
    "    BA = [A[0] - B[0], A[1] - B[1]]\n",
    "    BC = [C[0] - B[0], C[1] - B[1]]\n",
    "    print('BA',BA)\n",
    "    print('BC',BC)\n",
    "    dot_product = BA[0] * BC[0] + BA[1] * BC[1]\n",
    "    dot_product = torch.round(dot_product * 10000) / 10000\n",
    "    mod_BA = math.sqrt(BA[0]**2 + BA[1]**2)\n",
    "    mod_BC = math.sqrt(BC[0]**2 + BC[1]**2)\n",
    "    print('dot_product',dot_product)\n",
    "    print('mod_AB * mod_BC',mod_BA * mod_BC)\n",
    "    mod=mod_BA * mod_BC\n",
    "    mod = round(mod, 4)\n",
    "#     temp1=BA[0]+BC[0]+BA[1]+BC[1]\n",
    "#     print('temp1',temp1)\n",
    "#     if temp1==0:\n",
    "#         angle_degree=180\n",
    "#     else:\n",
    "    angle = math.acos(dot_product / mod)\n",
    "    angle_degree=math.degrees(angle)\n",
    "    if angle_degree>90 :\n",
    "        condition1=1\n",
    "    else:\n",
    "        condition1=0\n",
    "    \n",
    "    d_x=C[0]-B[0]\n",
    "    d_y=C[1]-B[1]\n",
    "    condition2=1\n",
    "    if d_x>0.2 or d_y>0.2 :\n",
    "        condition2=0\n",
    "    if condition1 and condition2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a80c8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.data_get_if:\n",
    "    if args.data_delete_if:\n",
    "        df_new=[]\n",
    "        for _, group in grouped_first:\n",
    "        #     print(group.shape)\n",
    "            df_train=torch.tensor(group.values)\n",
    "            T_temp=df_train.shape[0]\n",
    "            df_train_new=c(df_train)\n",
    "            df_train_new[0,:]=df_train[0,:]\n",
    "            df_train_new[1,:]=df_train[1,:]\n",
    "            n=2\n",
    "            for t_temp in range(2,T_temp):\n",
    "                if my_judge(df_train[t_temp,2:4],df_train[t_temp-1,2:4],df_train[t_temp-2,2:4]):\n",
    "                    df_train_new[n,:]=df_train[t_temp,:]\n",
    "                    n=n+1\n",
    "\n",
    "            df_train_new=df_train_new[:n,:]\n",
    "\n",
    "            df_new.append(df_train_new)\n",
    "\n",
    "\n",
    "        df_new = torch.cat(df_new, dim=0)    \n",
    "\n",
    "        df=pd.DataFrame(df_new.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32856be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('df_new.shape',df_new.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ed1b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "columns_to_normalize = df.columns[2:]\n",
    "df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
    "#         joblib.dump(scaler, 'scaler.joblib')\n",
    "mean_Longitude = scaler.mean_[0]\n",
    "std_Longitude = scaler.scale_[0]\n",
    "mean_Latitude = scaler.mean_[1]\n",
    "std_Latitude = scaler.scale_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1322e0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284030, 12)\n"
     ]
    }
   ],
   "source": [
    "if args.data_delete_if and args.data_get_if:\n",
    "    print(df.shape)\n",
    "    grouped = df.groupby(0, sort=False)\n",
    "    len(grouped)\n",
    "else:\n",
    "    print(df.shape)\n",
    "    grouped = df.groupby('track', sort=False)\n",
    "    len(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "645b0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda=True\n",
    "gpu=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a0d8d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"batch_size\": 64,            #三联损失时，一个batch的数量\n",
    "    \"channels\": 30,\n",
    "    \"compared_length\": None,\n",
    "    \"depth\": 10,\n",
    "    \"nb_steps\": 5,               # epoch次数\n",
    "    \"in_channels\": 8,#---------\n",
    "    \"kernel_size\": 3,\n",
    "    \"penalty\": None,\n",
    "    \"early_stopping\": None,\n",
    "    \"lr\": 0.001,\n",
    "    \"nb_random_samples\": 10,    # 负样本来源的batch数\n",
    "    \"negative_penalty\": 1,\n",
    "    \"out_channels\": 160,\n",
    "    \"reduced_size\": 80,\n",
    "    \"cuda\": cuda,\n",
    "    \"gpu\": gpu\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa150120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CausalCNNEncoderClassifier(batch_size=64, channels=30, compared_length=inf,\n",
       "                           cuda=True, depth=10, in_channels=8, kernel_size=3,\n",
       "                           nb_steps=5, out_channels=160, penalty=None,\n",
       "                           reduced_size=80)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CausalCNNEncoderClassifier</label><div class=\"sk-toggleable__content\"><pre>CausalCNNEncoderClassifier(batch_size=64, channels=30, compared_length=inf,\n",
       "                           cuda=True, depth=10, in_channels=8, kernel_size=3,\n",
       "                           nb_steps=5, out_channels=160, penalty=None,\n",
       "                           reduced_size=80)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CausalCNNEncoderClassifier(batch_size=64, channels=30, compared_length=inf,\n",
       "                           cuda=True, depth=10, in_channels=8, kernel_size=3,\n",
       "                           nb_steps=5, out_channels=160, penalty=None,\n",
       "                           reduced_size=80)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_yearly = scikit_wrappers.CausalCNNEncoderClassifier()\n",
    "encoder_yearly.set_params(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85fabe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "window=int(args.rep_triloss_len/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3dd158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.data_get_if:\n",
    "    if args.representation_if:\n",
    "        args.feature_num=160\n",
    "        args.dec_in=160\n",
    "        data_loss = MyDataset(grouped, x_step=args.rep_triloss_len,y_step=7)  # x的时间段为21，y的时间段为7\n",
    "        data_loss_x=data_loss[:][0]\n",
    "        print(data_loss_x.shape)\n",
    "        data_loss_x = data_loss_x.permute(0, 2, 1)\n",
    "        data_loss_x = data_loss_x.numpy()\n",
    "        data_loss_x = data_loss_x.astype(np.float64)\n",
    "        encoder_yearly.fit_encoder(data_loss_x, save_memory=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09fc41fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if args.data_get_if:\n",
    "    if args.representation_if:        \n",
    "        represent_data=[]\n",
    "        for _, group in grouped:\n",
    "        #     print(group.shape)\n",
    "            df_train=torch.tensor(group.values)\n",
    "            df_train=df_train.unsqueeze(0)\n",
    "            df_train = df_train.permute(0, 2, 1)\n",
    "            df_train=df_train[:,:10,:]                  # 10表示 2个id和时间戳  + 8维特征\n",
    "            print('df_train',df_train.shape)\n",
    "            train_features_day = encoder_yearly.encode_window(df_train, window)\n",
    "            print('train_features_day',train_features_day.shape)\n",
    "            represent_data.append(train_features_day)\n",
    "\n",
    "        represent_data = torch.cat(represent_data, dim=2)\n",
    "        print(represent_data.shape)\n",
    "        represent_data=represent_data.squeeze()\n",
    "        represent_data = represent_data.permute(1, 0)\n",
    "        print(represent_data.shape)\n",
    "        represent_data = pd.DataFrame(represent_data.numpy())\n",
    "        data_traj=represent_data\n",
    "    else:\n",
    "    #     data_traj=df\n",
    "        no_represent_data=[]                 # 为了与表示学习的数据量一致，便于可视化对比，这边做一个窗口删减\n",
    "        for _, group in grouped:\n",
    "        #     print(group.shape)\n",
    "            df_train=torch.tensor(group.values)\n",
    "            df_train=df_train.unsqueeze(0)\n",
    "            df_train = df_train.permute(0, 2, 1)\n",
    "            df_train=df_train[:,:10,:]                  # 10表示 2个id和时间戳  + 8维特征\n",
    "            print('df_train',df_train.shape)\n",
    "    #         train_features_day=df_train[:,:,:np.shape(df_train)[2] - window+1]\n",
    "            train_features_day=df_train[:,:,window-1:]\n",
    "    #         train_features_day = encoder_yearly.encode_window(df_train, 20)\n",
    "    #         print('train_features_day',train_features_day.shape)\n",
    "            no_represent_data.append(train_features_day)\n",
    "        no_represent_data = torch.cat(no_represent_data, dim=2)\n",
    "        print(no_represent_data.shape)\n",
    "        no_represent_data=no_represent_data.squeeze()\n",
    "        no_represent_data = no_represent_data.permute(1, 0)\n",
    "        print(no_represent_data.shape)\n",
    "        no_represent_data = pd.DataFrame(no_represent_data.numpy())\n",
    "        data_traj=no_represent_data     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe48fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "        \n",
    "if args.data_get_if:   \n",
    "    dset = my_TrajectoryDataset_csv(\n",
    "        data_traj,args,\n",
    "        obs_len=args.obs_len,\n",
    "        pred_len=args.pred_len,\n",
    "        skip=args.window_skip,\n",
    "        rel_if=args.rel_if)\n",
    "    train_ratio = 0.6  # 训练集比例\n",
    "    val_ratio = 0.2    # 验证集比例\n",
    "    test_ratio = 0.2   # 测试集比例\n",
    "\n",
    "    # 计算划分的样本数量\n",
    "    total_samples = len(dset)\n",
    "    train_size = int(train_ratio * total_samples)\n",
    "    val_size = int(val_ratio * total_samples)\n",
    "    test_size = total_samples - train_size - val_size\n",
    "\n",
    "\n",
    "    torch.manual_seed(3407)\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dset, [train_size, val_size, test_size])\n",
    "    if args.representation_if:\n",
    "        with open('./data/rep/train_dataset.pkl', 'wb') as f:\n",
    "            pickle.dump(train_dataset, f)\n",
    "        with open('./data/rep/val_dataset.pkl', 'wb') as f:\n",
    "            pickle.dump(val_dataset, f)\n",
    "        with open('./data/rep/test_dataset.pkl', 'wb') as f:\n",
    "            pickle.dump(test_dataset, f)\n",
    "    else:\n",
    "        with open('./data/train_dataset.pkl', 'wb') as f:\n",
    "            pickle.dump(train_dataset, f)\n",
    "        with open('./data/val_dataset.pkl', 'wb') as f:\n",
    "            pickle.dump(val_dataset, f)\n",
    "        with open('./data/test_dataset.pkl', 'wb') as f:\n",
    "            pickle.dump(test_dataset, f)\n",
    "        \n",
    "        \n",
    "else:\n",
    "    if args.representation_if:\n",
    "        with open('./data/rep/train_dataset.pkl', 'rb') as f:\n",
    "            train_dataset= pickle.load(f)\n",
    "        with open('./data/rep/val_dataset.pkl', 'rb') as f:\n",
    "            val_dataset= pickle.load(f)\n",
    "        with open('./data/rep/test_dataset.pkl', 'rb') as f:\n",
    "            test_dataset= pickle.load(f)\n",
    "    else:\n",
    "        with open('./data/train_dataset.pkl', 'rb') as f:\n",
    "            train_dataset= pickle.load(f)\n",
    "        with open('./data/val_dataset.pkl', 'rb') as f:\n",
    "            val_dataset= pickle.load(f)\n",
    "        with open('./data/test_dataset.pkl', 'rb') as f:\n",
    "            test_dataset= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc2fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58e881a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "torch.Size([15, 2, 160])\n",
      "torch.Size([7, 2, 160])\n",
      "tensor([[[ 2.0260e-01,  1.9570e-01, -4.9400e-02,  ..., -4.7200e-02,\n",
      "           7.0000e-04,  1.5610e-01],\n",
      "         [-1.4950e-01,  8.7120e-01,  9.7500e-02,  ..., -2.8300e-02,\n",
      "          -6.8500e-02,  2.0470e-01]],\n",
      "\n",
      "        [[ 1.8790e-01,  2.0250e-01, -3.4100e-02,  ..., -3.8800e-02,\n",
      "          -2.3000e-03,  1.6940e-01],\n",
      "         [-1.5780e-01,  8.6550e-01,  6.6200e-02,  ..., -4.1700e-02,\n",
      "          -2.9400e-02,  1.9470e-01]],\n",
      "\n",
      "        [[ 1.7520e-01,  1.9380e-01, -2.4100e-02,  ..., -7.0400e-02,\n",
      "          -1.4000e-02,  1.7460e-01],\n",
      "         [-1.7280e-01,  8.6230e-01,  6.5100e-02,  ..., -6.5100e-02,\n",
      "          -1.4100e-02,  2.0390e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.0000e-03,  1.4100e-01, -6.2000e-02,  ..., -1.9600e-02,\n",
      "           1.3900e-02,  1.3170e-01],\n",
      "         [-4.2490e-01,  7.6140e-01, -6.9900e-02,  ...,  8.6000e-03,\n",
      "           1.2590e-01,  7.1900e-02]],\n",
      "\n",
      "        [[-1.9800e-02,  1.3520e-01, -8.4400e-02,  ...,  1.2000e-03,\n",
      "           2.9500e-02,  1.4590e-01],\n",
      "         [-4.2580e-01,  7.6210e-01, -4.3900e-02,  ...,  1.0700e-02,\n",
      "           1.1940e-01, -1.8000e-03]],\n",
      "\n",
      "        [[-3.5800e-02,  1.2930e-01, -7.4600e-02,  ..., -1.7100e-02,\n",
      "           4.8000e-03,  1.5480e-01],\n",
      "         [-4.3890e-01,  7.5440e-01, -2.5200e-02,  ...,  1.8700e-02,\n",
      "           1.3640e-01, -1.9900e-02]]])\n",
      "tensor([[[-0.0519,  0.1196, -0.0386,  ..., -0.0348,  0.0218,  0.1485],\n",
      "         [-0.4514,  0.7500, -0.0771,  ...,  0.0448,  0.1742, -0.0150]],\n",
      "\n",
      "        [[-0.0678,  0.1162, -0.0323,  ..., -0.0652, -0.0023,  0.1573],\n",
      "         [-0.4663,  0.7591,  0.0029,  ..., -0.0086,  0.1675, -0.0697]],\n",
      "\n",
      "        [[-0.0830,  0.1102, -0.0182,  ..., -0.0635,  0.0081,  0.1856],\n",
      "         [-0.4893,  0.7526, -0.0263,  ...,  0.0012,  0.1850, -0.0737]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1033,  0.0982, -0.0028,  ..., -0.0517,  0.0343,  0.2130],\n",
      "         [-0.5164,  0.7649, -0.0066,  ..., -0.0532,  0.1749, -0.0620]],\n",
      "\n",
      "        [[-0.1180,  0.0945, -0.0198,  ..., -0.0334,  0.0396,  0.2246],\n",
      "         [-0.5356,  0.7596,  0.0229,  ..., -0.0245,  0.1916, -0.0041]],\n",
      "\n",
      "        [[-0.1332,  0.0905, -0.0354,  ..., -0.0615,  0.0492,  0.2159],\n",
      "         [-0.5529,  0.7656,  0.0851,  ..., -0.0644,  0.2340,  0.0199]]])\n"
     ]
    }
   ],
   "source": [
    "for cnt, batch in enumerate(train_dataset):\n",
    "    print(cnt)\n",
    "    print(len(batch))\n",
    "    print(batch[0].shape)  # T-N-F\n",
    "    print(batch[1].shape)\n",
    "    print(batch[0])\n",
    "    print(batch[1])\n",
    "#     print(batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64e5c253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True) # 在不同epoch再次打乱\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)  # 这里不打乱，从而方便可视化复现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d245c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9905fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=make_model(device,dilation_factor=args.dilation_factor,Encoder_SGCN=args.Encoder_SGCN,Encoder_ESG=args.Encoder_ESG,output_TCN=args.output_TCN,output_informer=args.output_informer,output_LSTM=args.output_LSTM,\n",
    "                 encoder_embedding=args.encoder_embedding,decoder_embedding=args.decoder_embedding,\n",
    "                 dec_in=args.dec_in,dim_hid=args.dim_hid,dim_out=args.dim_out,obs_len=args.obs_len,pred_len=args.pred_len,  \n",
    "                 layernorm_size=args.layernorm_size, \n",
    "                 num_layers_E=args.num_layers_E,num_layers_d=args.num_layers_d,dropout=args.dropout,residual_connection=args.residual_connection,\n",
    "                 use_LayerNorm=args.use_LayerNorm,use_generator=args.use_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d90e8ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mae(preds, labels, null_val=np.nan):\n",
    "    if np.isnan(null_val):\n",
    "        mask = ~torch.isnan(labels)\n",
    "    else:\n",
    "        mask = (labels!=null_val)\n",
    "    mask = mask.float()\n",
    "    mask /=  torch.mean((mask))\n",
    "    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n",
    "  \n",
    "    loss = torch.abs(preds-labels)\n",
    "    loss = loss * mask\n",
    "    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf100c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6101f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89fa18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4004151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion_train=my_mae().to(device)\n",
    "criterion = nn.modules.L1Loss(reduction='mean').to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e4350f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c97061ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mae(preds, labels, null_val=np.nan):   # B-T-N-2\n",
    "    all_loss=0\n",
    "    for t_pred in range(args.pred_len):\n",
    "        loss = F.mse_loss(preds[:,t_pred,:,:],labels[:,t_pred,:,:], reduction='mean').sqrt()\n",
    "        loss = loss*np.exp(-t_pred)\n",
    "        all_loss=all_loss+loss\n",
    "    all_loss=all_loss/(np.exp(0)+np.exp(-1)+np.exp(-2)+np.exp(-3)+np.exp(-4)+np.exp(-5)+np.exp(-6))\n",
    "    loss_var=criterion(torch.var(preds, dim=1),torch.var(labels, dim=1))\n",
    "    my_loss=all_loss+0.01*loss_var\n",
    "    return my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54e919b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2476504"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nParams = sum([p.nelement() for p in model.parameters()])\n",
    "nParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0b34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94779f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saves/LSTM\n",
      "./saves/LSTM\\representation\\Encoder_ESG\\Encoder_SGCN\\MSE\n"
     ]
    }
   ],
   "source": [
    "if args.output_TCN:\n",
    "    save_folder = os.path.join('./saves/TCN')\n",
    "elif args.output_LSTM:\n",
    "    save_folder = os.path.join('./saves/LSTM')\n",
    "elif  args.output_informer:\n",
    "    save_folder = os.path.join('./saves/informer')\n",
    "else :\n",
    "    save_folder = os.path.join('./saves')\n",
    "print(save_folder)\n",
    "if args.representation_if:\n",
    "    save_folder = os.path.join(save_folder,'representation')\n",
    "if args.Encoder_ESG:\n",
    "    save_folder = os.path.join(save_folder,'Encoder_ESG')\n",
    "if args.Encoder_SGCN:\n",
    "    save_folder = os.path.join(save_folder,'Encoder_SGCN')\n",
    "if args.MSE_if:\n",
    "    save_folder = os.path.join(save_folder,'MSE')\n",
    "print(save_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c83e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f09430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "model_path = os.path.join(save_folder,'best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7c6716e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saves/LSTM\\representation\\Encoder_ESG\\Encoder_SGCN\\MSE\\best-model.pt\n"
     ]
    }
   ],
   "source": [
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7654eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train=args.do_train ## 更换为True后，会覆盖当前保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3f351f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length=len(train_dataloader)\n",
    "val_length=len(val_dataloader)\n",
    "test_length=len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573cf271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8df32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6ebca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(data, model, criterion, optim, batch_size):\n",
    "    print('begin valing')\n",
    "    model.eval()\n",
    "    total_loss =[]\n",
    "\n",
    "    iter = 0\n",
    "    for cnt, batch in enumerate(data):\n",
    "        labels=batch[1][:,:,:,:2].to(device)\n",
    "        encoder_raw_input=batch[0].to(device)\n",
    "        if args.output_informer:\n",
    "            dec_inp_zero = torch.zeros([batch[1].shape[0], args.pred_len,batch[1].shape[2],batch[1].shape[3]]).float()\n",
    "            decoder_raw_input=torch.cat([batch[0][:,-args.teacher_len:,:,:], dec_inp_zero], dim=1).float().to(device)\n",
    "            output=model(encoder_raw_input,decoder_raw_input)\n",
    "            pred=output[:,-args.pred_len:,:,:]\n",
    "        if args.output_LSTM: \n",
    "            decoder_raw_input=batch[0][:,-args.teacher_len:,:,:2].to(device)  # B-T_teacher-N-2\n",
    "            ZC=model.my_channel_learn(encoder_raw_input)\n",
    "            encoder_output = model.encode(ZC)                                # B-T-N-256\n",
    "            Teacher=True\n",
    "            decoder_output=model.decode(decoder_raw_input, encoder_output,labels,Teacher,'val')  # return:(pred_len, N,B, 2)\n",
    "            pred=torch.permute(decoder_output,(2,0,1,3)).to(device)    # B-T-N-2\n",
    "                     \n",
    "        pred[:, :,:,0] = pred[:, :,:,0] * std_Longitude + mean_Longitude   ## 反向标准化\n",
    "        labels[:, :,:,0]  = labels[:, :,:,0]  * std_Longitude + mean_Longitude\n",
    "        pred[:, :,:,1]  = pred[:, :,:,1]  * std_Latitude + mean_Latitude\n",
    "        labels[:, :,:,1] = labels[:, :,:,1]  * std_Latitude + mean_Latitude\n",
    "        loss = F.mse_loss(pred, labels, reduction='mean').sqrt()+F.l1_loss(pred, labels)+F.mse_loss(pred, labels)+F.mse_loss(pred[:,-1], labels[:,-1], reduction='mean').sqrt()\n",
    "        loss=loss/4\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "\n",
    "            \n",
    "        iter += 1\n",
    "    return np.mean(total_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "650cda58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, model, criterion, optim, batch_size,epoch_start_time):\n",
    "    print('begin training')\n",
    "    model.train()\n",
    "    optim.zero_grad()\n",
    "    train_total_loss =[]\n",
    "    batch_count = 0\n",
    "    is_fst_loss = True\n",
    "    if args.use_amp:\n",
    "        GradScaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "    turn_point = int(train_length / args.batch_loss) * args.batch_loss + train_length % args.batch_loss - 1\n",
    "    \n",
    "    iter = 0\n",
    "    for cnt, batch in enumerate(data):\n",
    "        batch_count += 1\n",
    "        model.zero_grad()\n",
    "        labels=batch[1][:,:,:,:2].to(device)   # B-7-N-2\n",
    "        encoder_raw_input=batch[0].to(device)\n",
    "        if args.output_informer:\n",
    "            dec_inp_zero = torch.zeros([batch[1].shape[0], args.pred_len,batch[1].shape[2],batch[1].shape[3]]).float()\n",
    "            decoder_raw_input=torch.cat([batch[0][:,-args.teacher_len:,:,:], dec_inp_zero], dim=1).float().to(device)\n",
    "            output=model(encoder_raw_input,decoder_raw_input)\n",
    "            pred=output[:,-args.pred_len:,:,:]\n",
    "        if args.output_LSTM: \n",
    "            decoder_raw_input=batch[0][:,-args.teacher_len:,:,:2].to(device)  # B-T_teacher-N-2\n",
    "            ZC=model.my_channel_learn(encoder_raw_input)\n",
    "            encoder_output = model.encode(ZC)                                # B-T-N-256\n",
    "            Teacher=False\n",
    "            decoder_output=model.decode(decoder_raw_input, encoder_output,labels,Teacher,'train')  # return:(pred_len, N,B, 2)\n",
    "            pred=torch.permute(decoder_output,(2,0,1,3)).to(device)    # B-T-N-2\n",
    "#             print(decoder_output)\n",
    "#             print('decoder_raw_input.shape',decoder_raw_input.shape)\n",
    "#             print('pred',pred)\n",
    "#             print('labels',labels)\n",
    "        if args.train_without_stand :            \n",
    "            pred[:, :,:,0] = pred[:, :,:,0] * std_Longitude + mean_Longitude   ## 反向标准化\n",
    "            labels[:, :,:,0]  = labels[:, :,:,0]  * std_Longitude + mean_Longitude\n",
    "            pred[:, :,:,1]  = pred[:, :,:,1]  * std_Latitude + mean_Latitude\n",
    "            labels[:, :,:,1] = labels[:, :,:,1]  * std_Latitude + mean_Latitude\n",
    "        if args.MSE_if:\n",
    "            loss = my_mae(pred,labels)                  \n",
    "        else:\n",
    "            loss = F.mse_loss(pred, labels, reduction='mean').sqrt()\n",
    "            \n",
    "        if args.use_amp:\n",
    "            optimizer.zero_grad()\n",
    "            GradScaler.scale(loss).backward()\n",
    "            train_total_loss.append(loss.item())\n",
    "            GradScaler.step(optim)\n",
    "            GradScaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            train_total_loss.append(loss.item())\n",
    "            grad_norm = optim.step()\n",
    "            \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                if torch.isinf(param.grad).any():\n",
    "                    print(f\"Parameter {name} has gradients containing infinite values.\")\n",
    "\n",
    "#         print()\n",
    "#         if batch_count % args.batch_loss != 0 and cnt != turn_point:\n",
    "#             l = criterion(pred,labels)   \n",
    "\n",
    "#             if is_fst_loss:\n",
    "#                 loss = l\n",
    "# #                 print('here',loss)\n",
    "#                 is_fst_loss = False\n",
    "#             else:\n",
    "#                 loss += l\n",
    "        \n",
    "#         else:\n",
    "#             loss = loss / args.batch_loss\n",
    "#             is_fst_loss = True\n",
    "#             loss.backward()        \n",
    "#             train_total_loss.append(loss.item())\n",
    "#             grad_norm = optim.step()        \n",
    "        \n",
    "        t2 = time.time()\n",
    "        if iter%100==0:\n",
    "\n",
    "            print('train batch %s / %s, loss: %.2f' % (iter + 1, train_length, loss.item()))\n",
    "            print('time: %.2f'%(t2-epoch_start_time))\n",
    "        iter += 1\n",
    "    return np.mean(train_total_loss) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6b10515",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.do_train_from_last:\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68dd3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(model_path, 'rb') as f:\n",
    "#     model = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb56ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_train:\n",
    "    best_val = 10000000\n",
    "    best_epoch = 10000\n",
    "    for epoch in range(1, args.epochs + 1, 1):\n",
    "        print('epoch:',epoch,flush=True)\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        train_loss= train(train_dataloader, model, criterion, optimizer, args.batch_size,epoch_start_time)\n",
    "        print('train_loss:',train_loss)\n",
    "\n",
    "    # #————————————————————————————————————————————————————————\n",
    "\n",
    "        val_loss= val(val_dataloader, model, criterion, optimizer, args.batch_size)\n",
    "        print(\n",
    "            '| end of epoch {:3d} | time: {:5.2f}s | train_loss {:5.4f} | valid rse {:5.4f} '.format(\n",
    "                epoch, (time.time() - epoch_start_time), train_loss,val_loss), flush=True)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "    # #————————————————————————————————————————————————————————\n",
    "        if val_loss < best_val:\n",
    "            print('save the model at epoch ' + str(epoch)+'*********')\n",
    "            with open( model_path, 'wb') as f:\n",
    "                print('save model epoch%s',epoch)\n",
    "                torch.save(model, f)    \n",
    "            best_val = val_loss\n",
    "            best_epoch = epoch\n",
    "#         elif args.early_stop and  epoch - best_epoch > args.early_stop_steps:\n",
    "#             print('best epoch:', best_epoch)\n",
    "#             raise ValueError('Early stopped.')\n",
    "    # #————————————————————————————————————————————————————————\n",
    "\n",
    "    print('best epoch:', best_epoch)   \n",
    "else:\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ef522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ffabac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ecfe7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.output_TCN:\n",
    "    result_folder = os.path.join('./results/TCN')\n",
    "elif args.output_LSTM:\n",
    "    result_folder = os.path.join('./results/LSTM')\n",
    "elif args.output_informer:\n",
    "    result_folder = os.path.join('./results/informer')    \n",
    "else :\n",
    "    result_folder = os.path.join('./results')\n",
    "    \n",
    "if args.representation_if:\n",
    "    result_folder = os.path.join(result_folder,'representation')    \n",
    "if args.Encoder_ESG:\n",
    "    result_folder = os.path.join(result_folder,'Encoder_ESG')\n",
    "if args.Encoder_SGCN:\n",
    "    result_folder = os.path.join(result_folder,'Encoder_SGCN')\n",
    "if args.MSE_if:\n",
    "    result_folder = os.path.join(result_folder,'MSE')\n",
    "if not os.path.exists(result_folder):\n",
    "    os.makedirs(result_folder)\n",
    "result_path_txt = os.path.join(result_folder,'results.txt')\n",
    "result_path_figure= os.path.join(result_folder,'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c49b31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(model_path, 'rb') as f:\n",
    "#     model = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747c8326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "946e4c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ade(predicted_traj, true_traj):\n",
    "\n",
    "    displacement = torch.sqrt(torch.sum((predicted_traj - true_traj) ** 2, dim=2))\n",
    "    \n",
    "    ade = torch.mean(displacement)\n",
    "    \n",
    "    return ade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5c6d6fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "real=[]\n",
    "history=[]\n",
    "prediction_prob=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "57c24fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_gailv=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e1e8563d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test batch 1 / 274, loss: 0.08\n",
      "test batch 101 / 274, loss: 0.11\n",
      "test batch 201 / 274, loss: 0.13\n",
      "test_loss: 0.09271637993780049\n",
      "mae: 0.09271637993780049\n",
      "mse: 0.021686282812998715\n",
      "ade: 0.165135026472536\n",
      "fde: 0.2281297199834477\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_loss =[]\n",
    "total_MAE =[]\n",
    "total_MSE =[]\n",
    "total_ADE =[]\n",
    "total_FDE =[]\n",
    "iter = 0\n",
    "for cnt, batch in enumerate(test_dataloader):\n",
    "    labels=batch[1][:,:,:,:2].to(device)\n",
    "    encoder_raw_input=batch[0].to(device)\n",
    "    if args.output_informer:\n",
    "        dec_inp_zero = torch.zeros([batch[1].shape[0], args.pred_len,batch[1].shape[2],batch[1].shape[3]]).float()\n",
    "        decoder_raw_input=torch.cat([batch[0][:,-args.teacher_len:,:,:], dec_inp_zero], dim=1).float().to(device)\n",
    "        output=model(encoder_raw_input,decoder_raw_input)\n",
    "        pred=output[:,-args.pred_len:,:,:]\n",
    "        pred[:, :,:,0] = pred[:, :,:,0] * std_Longitude + mean_Longitude   \n",
    "        pred[:, :,:,1]  = pred[:, :,:,1]  * std_Latitude + mean_Latitude\n",
    "    if args.output_LSTM: \n",
    "        decoder_raw_input=batch[0][:,-args.teacher_len:,:,:2].to(device)  # B-T_teacher-N-2\n",
    "        ZC=model.my_channel_learn(encoder_raw_input)\n",
    "        encoder_output = model.encode(ZC)                                # B-T-N-256\n",
    "        Teacher=True\n",
    "        if photo_gailv:\n",
    "            decoder_output,log_prob=model.decode(decoder_raw_input, encoder_output,labels,Teacher,'test')  # return:(pred_len, N,B, 2)\n",
    "            pred_all=torch.permute(decoder_output,(2,0,1,3)).to(device)    # B-T-N-2\n",
    "            log_prob=torch.permute(log_prob,(2,0,1,3)).to(device)    # B-T-N-1\n",
    "\n",
    "            pred_all[:, :,:,0] = pred_all[:, :,:,0] * std_Longitude + mean_Longitude   \n",
    "            pred_all[:, :,:,1]  = pred_all[:, :,:,1]  * std_Latitude + mean_Latitude\n",
    "            pred=pred_all[:1,:,:,:]\n",
    "        else:\n",
    "            decoder_output=model.decode(decoder_raw_input, encoder_output,labels,Teacher,'train')  # return:(pred_len, N,B, 2)\n",
    "            pred=torch.permute(decoder_output,(2,0,1,3)).to(device)    # B-T-N-2\n",
    "            pred[:, :,:,0] = pred[:, :,:,0] * std_Longitude + mean_Longitude   \n",
    "            pred[:, :,:,1]  = pred[:, :,:,1]  * std_Latitude + mean_Latitude\n",
    "            \n",
    "    labels[:, :,:,0]  = labels[:, :,:,0]  * std_Longitude + mean_Longitude\n",
    "\n",
    "    labels[:, :,:,1] = labels[:, :,:,1]  * std_Latitude + mean_Latitude\n",
    "#     print(pred.shape)\n",
    "#     print(labels.shape)\n",
    "\n",
    "    loss = criterion(pred,labels)                  \n",
    "    total_loss.append(loss.item())\n",
    "    \n",
    "    mae =F.l1_loss(pred, labels)\n",
    "    total_MAE.append(mae.item())    \n",
    "    \n",
    "    mse = F.mse_loss(pred, labels)\n",
    "    total_MSE.append(mse.item())\n",
    "    \n",
    "    ade=calculate_ade(pred, labels)\n",
    "    total_ADE.append(ade.item())\n",
    "    \n",
    "    fde=calculate_ade(pred[:,-1], labels[:,-1])\n",
    "    total_FDE.append(fde.item())\n",
    "    \n",
    "    if iter%100==0:\n",
    "      \n",
    "        print('test batch %s / %s, loss: %.2f' % (iter + 1, val_length, loss.item()))\n",
    "\n",
    "    iter += 1\n",
    "    \n",
    "\n",
    "    if photo_gailv:\n",
    "        prob_all = torch.cat((pred_all, log_prob), dim=-1)     # B-T-N-3\n",
    "        prob_all=torch.permute(prob_all,(0,2,1,3)) # B-N-T-F    \n",
    "        prediction_prob.append(prob_all.detach().cpu().numpy())   \n",
    "    \n",
    "    encoder_raw_input[:, :,:,0]  = encoder_raw_input[:, :,:,0]  * std_Longitude + mean_Longitude\n",
    "    encoder_raw_input[:, :,:,1] = encoder_raw_input[:, :,:,1]  * std_Latitude + mean_Latitude\n",
    "    \n",
    "    \n",
    "#     min_lon_x=min(encoder_raw_input[:, :,:,0])\n",
    "#     min_lon_y=min(labels[:, :,:,0])\n",
    "#     min_lon_p=torch.min(pred_all[:, :,:,0])\n",
    "#     min_lon=min(min_lon_x,min_lon_y,min_lon_p)\n",
    "    \n",
    "    pred=torch.permute(pred,(0,2,1,3)) # B-N-T-F\n",
    "    labels=torch.permute(labels,(0,2,1,3)) # B-N-T-F\n",
    "    encoder_raw_input=torch.permute(encoder_raw_input,(0,2,1,3)) # B-N-T-F\n",
    "\n",
    "    \n",
    "    prediction.append(pred.detach().cpu().numpy())\n",
    "    real.append(labels.detach().cpu().numpy())   \n",
    "    history.append(encoder_raw_input[:,:,:,:2].detach().cpu().numpy())  \n",
    "\n",
    "#     break \n",
    "    \n",
    "print('test_loss:',np.mean(total_loss))\n",
    "print('mae:',np.mean(total_MAE))\n",
    "print('mse:',np.mean(total_MSE))\n",
    "print('ade:',np.mean(total_ADE))\n",
    "print('fde:',np.mean(total_FDE))\n",
    "masked_mae=np.mean(total_loss)\n",
    "with open(result_path_txt, 'a') as f:\n",
    "    f.write(f'masked_mae:{masked_mae}')\n",
    "    f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0893f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8f837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c06bb05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testtry333",
   "language": "python",
   "name": "testtry333"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
